# To clean the Global environment
rm(list=ls()) 

#############################################################
#####                     To read                       #####
#############################################################
# This R script is the fourth step after merging Scopus and Web of Sciences (BibTex format)
# This script allows a bibliometric analysis on the records and the countries

#############################################################
#####                 File requirement                  #####
#############################################################
# The files to be imported are generated by the first code Merger_1.R

library(dplyr)
library(stringr)
library(tidyr)
library(hablar)
library(ggplot2)
library(maps)
library(countrycode)
library(RColorBrewer)
library(bibliometrix)
library(tidyverse)
library(plotly)
library(extrafont)
library(ggpubr)

#############################################################
#####                      Function  1/2                #####
#############################################################

#### Function to search and replace ####

# Include function to duplicate {Marc Schwartz (via MN) on http://r.789695.n4.nabble.com/replace-values-in-data-frame-td803416.html}
gsr <- function(Source, Search, Replace) 
{ 
  if (length(Search) != length(Replace)) 
    stop("Search and Replace Must Have Equal Number of Items\n") 
  
  Changed <- as.character(Source) 
  
  for (i in 1:length(Search)) 
  { 
    cat("Replacing: ", Search[i], " With: ", Replace[i], "\n") 
    Changed <- replace(Changed, Changed == Search[i], Replace[i]) 
  } 
  
  cat("\n") 
  
  Changed 
}
#############################################################
#####                      Function  2/2                #####
#############################################################

# function to replace accented characters with unaccented equivalents 
# adapted from https://stackoverflow.com/questions/15253954/replace-multiple-letters-with-accents-with-gsub
removeDiacritics <- function(string) {
  chartr(
    "ŠŽšžŸÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝàáâãäåçèéêëìíîïðñòóôõöøùúûüýÿ",
    "SZszYAAAAAACEEEEIIIIDNOOOOOOUUUUYaaaaaaceeeeiiiidnoooooouuuuyy", 
    string
  )
}

#######################################################################
#####                         Data loading                        #####
#######################################################################

# set working directory

# read the export *.csv document from Merger, separation ",", and place it in data.frame "MergerOriginalData"
MergerOriginalData <- read.csv("Merger_Dataset_Final.txt", sep="\t", header=TRUE)


#############################################################
#####                Document analysis                  #####
#############################################################
#####__________________ Document Table ____________________#####
# create a new data.frame of the number of document published each year
document <- MergerOriginalData %>%
  select(PY,TI,AU,C1, DT)
# Change the column name
names(document) <- c("Year", "Title", "Authors", "Affiliation", "Document.Type")

#Count to number of time the same year is repeated in the "document$Year" and save in a data.frame "Year" 
year <- data.frame(table(document$Year));year
year$Var1 <- as.numeric(as.character(year$Var1))
names(year) <- c("Year","Total")

# Change the name of the type of document
# read the corrected list of "document" and combine it to the original list
DocumentCorrected <- read.csv("Document Type Name Corrected_ScopWoS.txt", sep="\t", header=TRUE)
document$Document.TypeC <- gsr(document$Document.Type, DocumentCorrected$name, as.character(DocumentCorrected$Name.Corrected))

document <- document%>%
  select(Year, Title, Authors, Affiliation, Document.TypeC)
# rename SOCorrected column
names(document)[names(document)=="Document.TypeC"] <- "Document.Type"

# To export data relative to document
DT <- data.frame(table(document$Document.Type, exclude = ""));DT
write.table(DT, file = "Document type_ScopWoS.csv", quote = F, sep = "\t", row.names = F)

# List of "Articles and their first "Year" of appearance
Articles <- filter(document, Document.Type=="ARTICLE")
ArticlesCount <- aggregate(Articles$Document.Type, list(Articles$Year), FUN=length)
names(ArticlesCount) <- c("Year","Articles")
# Add missing years
ArticlesCountExtended <- ArticlesCount %>%
  complete(Year = 1978:2020, fill = list(Freq = 0)) %>%
  as.data.frame()

Proceedings <- filter(document, Document.Type=="PROCEEDINGS")
ProceedingsCount <- aggregate(Proceedings$Document.Type, list(Proceedings$Year), FUN=length)
names(ProceedingsCount) <- c("Year","Proceedings")
# Add missing years
ProceedingsCountExtended <- ProceedingsCount %>%
  complete(Year = 1978:2020, fill = list(Freq = 0)) %>%
  as.data.frame()
ProceedingsCountExtended[is.na(ProceedingsCountExtended)] <- 0

Book <- filter(document, Document.Type=="BOOK CHAPTER" | Document.Type=="EDITORIAL MATERIAL; BOOK CHAPTER BOOK CHAPTER" )
BookCount <- aggregate(Book$Document.Type, list(Book$Year), FUN=length)
names(BookCount) <- c("Year","Books")
# Add missing years
BookCountExtended <- BookCount %>%
  complete(Year = 1978:2020, fill = list(Freq = 0)) %>%
  as.data.frame()
BookCountExtended[is.na(BookCountExtended)] <- 0

Conference <- filter(document, Document.Type=="CONFERENCE PAPER")
ConferenceCount <- aggregate(Conference$Document.Type, list(Conference$Year), FUN=length)
names(ConferenceCount) <- c("Year","Conference Paper")
# Add missing years
ConferenceCountExtended <- ConferenceCount %>%
  complete(Year = 1978:2020, fill = list(Freq = 0)) %>%
  as.data.frame()
ConferenceCountExtended[is.na(ConferenceCountExtended)] <- 0


Other <- filter(document, Document.Type=="BOOK CHAPTER" | Document.Type=="PROCEEDINGS" | Document.Type=="CONFERENCE PAPER" |  Document.Type=="ARTICLE" | Document.Type=="EDITORIAL MATERIAL; BOOK CHAPTER BOOK CHAPTER")
Other2 <- setdiff(document, Other)
OtherCount <- aggregate(Other2$Document.Type, list(Other2$Year), FUN=length)
names(OtherCount) <- c("Year","Others")
# Add missing years
OtherCountExtended <- OtherCount %>%
  complete(Year = 1978:2020, fill = list(Freq = 0)) %>%
  as.data.frame()
OtherCountExtended[is.na(OtherCountExtended)] <- 0

# Create a table to export it
Table2Output <- Reduce(merge, list(year, ArticlesCountExtended,ProceedingsCountExtended, BookCountExtended, OtherCountExtended))

# Statistics for each variables
summary(Table2Output)

#Export to text file
#write.table(Table2Output, file = "Document_Table.csv", sep = ",", row.names = F)

#####__________________Document per Year_________________#####

# To add years with no document
DFfilled <- year %>%
  complete(Year = 1978:2020,
           fill = list(Freq = 0)) %>%
  as.data.frame()
DFfilled
DFfilled[is.na(DFfilled)] <- 0

# To caculate the AAGR and CAGR
#write.csv(DFfilled,"Merger AAGR.csv")

# GRAPH
DocumentPerYear <-ggplot(DFfilled, aes(x =Year, y = Total)) +
  geom_smooth(method = 'lm', se=FALSE, color="red", size=0.5)+
  geom_line(data =DFfilled, aes(x =Year, y = Total), color = "black")+ geom_point(data =DFfilled, aes(x =Year, y = Total), color = "black")+
  ylim(0,40)+
  labs(x="Year", y="Number of references")+
  theme_bw(base_family = "Arial", base_size = 12)+
  theme(axis.text.x= element_text(angle= 90, vjust= 0.5),
        axis.title.x = element_text(colour="black", vjust=-2),
        axis.title.y = element_text(colour="black", vjust=3))
show(DocumentPerYear)
ggsave("DocumentPerYear.png", DocumentPerYear, width = 7, height = 4, units = "in", dpi=150, path = "Results")

#####__________________Top journal_________________#####

# Create new dataframe with only the first top 15 Journals
TopJournal <- data.frame(table(MergerOriginalData$SO, exclude = ""));TopJournal
TopJournal <- top_n(TopJournal, 15,Freq) 
TopJournal <- TopJournal[order(-TopJournal$Freq),]
names(TopJournal) <- c("Title","Frequency")

#Export to text file
#write.table(TopJournal, file = "TopJournal_Table.csv", sep = ",", row.names = F)

#############################################################
#####                    Countries                      #####
#############################################################

# get city/country data
data(world.cities)

# replace "United States" with USA & "United Kingdom" with UK.
aff.lst <- gsub("UNITED STATES$", "USA", MergerOriginalData$C1, perl = TRUE)  # toupper as affiliations in capital
aff.lst <- gsub("UNITED KINGDOM$", "UK", aff.lst, perl = TRUE)             # toupper as affiliations in capital
# replace ';' with ',' as multiple affiliations are separated with ';'
# but that doesn't fit with the strsplit()
aff.lst <- gsub(";", ",", aff.lst)
# split fields by ", "
splt.lst <- sapply(aff.lst, strsplit, split = ",", USE.NAMES = FALSE)
# extract fields which match a known city making sure that diacritics aren't a problem...
city.lst <- lapply(splt.lst, function(x)x[which(removeDiacritics(x) %in% toupper(world.cities$name))]) # toupper as affiliations in capital
# ... or country
# cntry.lst <- lapply(splt.lst, function(x)x[which(removeDiacritics(x) %in% toupper(world.cities$country.etc))]) # toupper as affiliations in capital
# this version only returns unique instances of countries per publication
cntry.lst <- lapply(splt.lst, function(x)unique(x[which(x %in%  toupper(world.cities$country.etc))]))  # toupper as affiliations in capital

## generate plot of papers per country
threshold <- 5
cntry.dat <- data.frame(Country = removeDiacritics(unlist(cntry.lst)), stringsAsFactors = FALSE)

# define continent for each country
cntry.dat$Continent <- countrycode(sourcevar = cntry.dat[, "Country"],
                                   origin = "country.name",
                                   destination = "continent")

# get countries under threshold
other.dat <- cntry.dat %>% 
  group_by(Country, Continent) %>% 
  summarise(Count = n()) %>% 
  filter(Count <= threshold)
# aggregate counts as 'Others'
other.dat <- data.frame(Country = "Others", Continent = "Other", Count = sum(other.dat$Count))

# Collate counts for countries over threshold
cntry.dat <- cntry.dat %>% 
  group_by(Country, Continent) %>% 
  summarise(Count = n()) %>% 
  filter(Count > threshold)
# order by count
cntry.dat$Country <- reorder(cntry.dat$Country, +cntry.dat$Count)
# add in 'Others'
cntry.dat <- rbind(other.dat, data.frame(cntry.dat))

# plot
p <- ggplot(cntry.dat, aes(x=Country, y=Count, fill=Continent)) + 
  geom_col() +
  scale_fill_manual(values = c("gray", brewer.pal(6, "Set1")), breaks = c("Americas", "Asia", "Europe", "Oceania","Africa", "Other")) +
  xlab('Country Affiliation') +
  ylab('Total Papers') +
  coord_flip() +
  theme_minimal() +
  theme(text = element_text(family = "Arial"))
show(p)
ggplotly(p)
ggsave("Country_ScopWoS.png", p, width = 8, height = 6, units = "in", dpi=150, path = "Results")

